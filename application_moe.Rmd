---
title: "Fish Permit Application"
author: "Al Irvine"
output:
  pagedown::html_letter:
    self_contained: true
    css: ["style-pagedown.css", "default", "letter"]
links-to-footnotes: false
paged-footnotes: false
# uncomment this line to produce HTML and PDF in RStudio:
knit: pagedown::chrome_print
---

![logo](fig/nge-full_black.png){.logo} 


 

<br>

::: from
Al Irvine  
New Graph Environment Ltd.  
al@newgraphenvironment   
250-777-1518  
Date: `r format(Sys.Date(), "%Y-%m-%d")` 
:::


Ministry of Environment  
1011 4th Ave   
Prince George, BC V2L 3H9




<br>

**Re: Fish Permit Application**

<br>

```{r setup, include = TRUE, echo =FALSE, message=FALSE, warning=FALSE}
# gitbook_on <- TRUE
gitbook_on <- FALSE  ##we just need turn  this on and off to switch between gitbook and pdf via paged.js


knitr::opts_chunk$set(echo=FALSE, message=FALSE, warning=FALSE, dpi=60, out.width = "100%")
options(scipen=999)
options(knitr.kable.NA = '--') #'--'
options(knitr.kable.NAN = '--')

source('R/packages.R')
source('R/functions.R')

name_project <- 'parsnip_2022'
name_repo <- 'fish_passage_parsnip_2022_permit'

link_repo <- paste0('https://newgraphenvironment.github.io/', name_repo, '/')
link_kml <- paste0('https://github.com/NewGraphEnvironment/', name_repo, '/raw/main/docs/sites_', name_project, '_', format(Sys.Date(), '%Y%m%d'), '_kml.zip')
```

```{r settings-gitbook, eval= gitbook_on}
photo_width <- "100%"
font_set <- 11

```

```{r settings-paged-html, eval= identical(gitbook_on, FALSE)}
photo_width <- "80%"
font_set <- 9
```

This permit application can also be viewed online [at this link](`r knitr::asis_output(link_repo)`).  A summary of sites to be potentially assessed is included as Table \@ref(tab:tab-sites),  details of fish species potentially encountered is presented in  Table \@ref(tab:tab-fish) and an overview map displaying potential sample locations is included as Figure 1. A kml file of the sites is included as an attachment to the application and can also be downloaded [from here at this link](`r knitr::asis_output(link_kml)`)
<br>

Rationale for sampling is to inform fish presence/absence and species composition/density as part of habitat confirmations to prioritize fish passage restoration at barrier culverts as per the [Fish Passage Technical Working Group Phase 2 protocol](https://www2.gov.bc.ca/gov/content/environment/natural-resource-stewardship/land-based-investment/investment-categories/fish-passage). Presence/absence of fish, species composition/density and distribution limits can be useful for prioritizing which crossings are a best fit for fish passage restoration and help inform follow up monitoring.  

<br>

Sampling is proposed at 2 or 3 sites included in Table \@ref(tab:tab-sites) where we will be performing habitat confirmations this summer.  Sample locations may occur well upstream or downstream of the crossing locations.  The current list of candidate streams will be narrowed down through the results of field assessments, modeling, ongoing communications with McLeod Lake, Lands and Natural ResourceOperation, Ministry of Environment and other stakeholders. Sampling methodologies will be dependent on the site, fish species suspected, type of habitat encountered, risks to aquatic organisms potentially present and ongoing communications.  Sampling methods may include minnowtrapping, electrofishing, and dipnetting upstream and downstream of barrier culvert locations. 

<br>


Please note that the sampling will be completed before October 31 however the period is listed as Dec 31 on the application to allow time outside of the busy field season for the data to be processed, QA'd and organized so that required reporting can be as informative as possible when submitted. An example of how we have been presenting results and methodologies from past assessments can be referenced [here at this link](https://newgraphenvironment.github.io/fish_passage_skeena_2021_reporting/).

<br>

Please do not hesitate to contact me if you have any questions or concerns.



![signature](/Users/airvine/Projects/current/Admin/Al_Sig.jpg){width=50%}  
Al Irvine, R.P.Bio 

```{r load}
# grab sites from the planning



##2019 phase 2 sites sites
sites_2020 <- fpr::fpr_import_pscis(workbook_name = 'pscis_phase2.xlsm') |> 
  tibble::rownames_to_column() |> 
  arrange(pscis_crossing_id) |> filter(!is.na(pscis_crossing_id)) |> 
  pull(pscis_crossing_id)

```

```{r pull-db}
##pull out what we need from the database
# see usethis::edit_r_environ

conn <- DBI::dbConnect(
  RPostgres::Postgres(),
  dbname = 'bcfishpass',
  host = 'localhost',
  port = '5432',
  user = 'postgres',
  password = 'postgres'
)

# grab the crossings data from bcfishpass
query = "SELECT * FROM bcfishpass.crossings WHERE watershed_group_code = 'PARS'"

bcfishpass <- sf::st_read(conn, 
                         query = query)

sites_for_review <- bcfishpass |> 
  filter(barrier_status != 'PASSABLE' &
           barrier_status != 'UNKNOWN') |> 
  # is.na(pscis_status)) %>% 
  filter(bt_rearing_km > 0.5 &
           crossing_subtype_code != 'BRIDGE' |
           (stream_crossing_id %in% sites_2020)) |> 
  mutate(pscis_phase = case_when(
    pscis_status == 'ASSESSED' ~ '1',
    T ~ '2'
  )) 



# grab the watershed codes
wscodes <- DBI::dbGetQuery(conn,
                      "SELECT DISTINCT ON (aggregated_crossings_id)
a.aggregated_crossings_id,
a.linear_feature_id,
a.watershed_group_code,
b.watershed_code_50k,
substring(b.watershed_code_50k from 1 for 3)
||'-'||substring(b.watershed_code_50k from 4 for 6)
||'-'||substring(b.watershed_code_50k from 10 for 5)
||'-'||substring(b.watershed_code_50k from 15 for 5)
||'-'||substring(b.watershed_code_50k from 20 for 4)
||'-'||substring(b.watershed_code_50k from 24 for 4)
||'-'||substring(b.watershed_code_50k from 28 for 3)
||'-'||substring(b.watershed_code_50k from 31 for 3)
||'-'||substring(b.watershed_code_50k from 34 for 3)
||'-'||substring(b.watershed_code_50k from 37 for 3)
||'-'||substring(b.watershed_code_50k from 40 for 3)
||'-'||substring(b.watershed_code_50k from 43 for 3) as watershed_code_50k_parsed,
b.blue_line_key_20k,
b.watershed_key_20k,
b.blue_line_key_50k,
b.watershed_key_50k,
b.match_type
FROM bcfishpass.crossings a
LEFT OUTER JOIN whse_basemapping.fwa_streams_20k_50k b
ON a.linear_feature_id = b.linear_feature_id_20k
WHERE a.watershed_group_code IN ('PARS')
ORDER BY a.aggregated_crossings_id, b.match_type;"
)  |> 
  filter(aggregated_crossings_id %in% (sites_for_review %>% pull(aggregated_crossings_id))) |> 
  rename(id = aggregated_crossings_id)

# make a table with the watershed codes, stream name, fish species
table_wsc_prep <- left_join(
  sites_for_review |> select(id = aggregated_crossings_id, gnis_stream_name, observedspp_upstr),
  wscodes |> select(id, watershed_code_50k_parsed),
  by = 'id'
) |> 
  # sf::st_drop_geometry() |> 
  arrange(id)

# we still need the name of the stream from the pscis file.
query = "SELECT * FROM whse_fish.pscis_assessment_svw"

pscis <- sf::st_read(conn, 
                         query = query) |> 
  sf::st_drop_geometry()
  
table_wsc <- left_join(
  table_wsc_prep,
  pscis |> select(id = stream_crossing_id, stream_name),
  by = 'id'
) |> 
  mutate(stream_name = case_when(
    is.na(stream_name) ~ gnis_stream_name,
    T ~ stream_name
  )) |> 
  select(id, 
         stream_name, 
         observedspp_upstr, 
         wsc_code = watershed_code_50k_parsed)

# make a gpx file table


# join all the wsc and crossings tables together
table_sites <- left_join(
  sites_for_review |> 
  select(id = aggregated_crossings_id, 
         pscis_phase, 
         barrier_status, 
         bt_network_km,
         bt_spawning_km,
         bt_rearing_km,
         utm_easting,
         utm_northing,
         mapsheet = dbm_mof_50k_grid,
         pscis_assessment_comment) |> 
  arrange(id),
 
   table_wsc |> sf::st_drop_geometry(),
  
  by = 'id'
) |> 
  sf::st_transform(crs = 4326) %>% 
  # we had to us the old magritter pipe here!
  mutate(long = sf::st_coordinates(.)[,1],
         lat = sf::st_coordinates(.)[,2])
```

```{r gpx}

dir.create('mapping')

#make a gpx file for loading into the gps'
sites_for_review |> 
  mutate(desc = 'bt_rearing_km') |> 
  select(name = aggregated_crossings_id, desc, geom) |> 
  sf::st_transform(crs = 4326) |> 
  write_sf(dsn = paste0("mapping/sites_", name_project, '_', format(Sys.Date(), "%Y%m%d"), ".gpx"), driver="GPX",
           dataset_options="GPX_USE_EXTENSIONS=yes", delete_dsn = TRUE)

```

```{r kml}
##make a kml for adding to the georef pdf and sharing with stakeholders

df <- table_sites %>%
  mutate(shape = 'http://maps.google.com/mapfiles/kml/paddle/red-blank.png',
         color = 'red',
         label = NA_character_) %>%
                           # color = plotKML::col2kml(color)) %>%
           dplyr::group_split(id) %>% 
           purrr::map(fpr::fpr_make_html_tbl) %>%
           dplyr::bind_rows()


sites_kml <- as(df, 'Spatial')

shape = "http://maps.google.com/mapfiles/kml/pal2/icon18.png"



kml_open(paste0("mapping/sites_", name_project, '_', format(Sys.Date(), "%Y%m%d"), '.kml'))
kml_layer(sites_kml, colour = '#ff7f00', shape = sites_kml$shape, labels = sites_kml$id, 
          html.table = sites_kml$html_tbl,
          z.scale = 2, LabelScale = 1, size = 1.5)  ##I don't see the label
kml_close(paste0("mapping/sites_", name_project, '_', format(Sys.Date(), "%Y%m%d"), '.kml'))

##now we will zip up the kml files in the data folder and rename with kmz
files_to_zip <- paste0("mapping/", list.files(path = "mapping/", pattern = "\\.kml$"))  ##this will zip all kmls in file so watch out
zip::zipr(paste0("docs/sites_", name_project, '_', format(Sys.Date(), "%Y%m%d"), '_kml.zip'), files = files_to_zip)  ##it does not work to zip to kmz!!


```



`r if(gitbook_on){knitr::asis_output("<br>")} else knitr::asis_output("<br><br><br><br><br><br><br>")`




```{r map-prep}


##register google key defined in 'R/private_info.R' file
# ggmap::register_google(key = google_api_key)
ggmap::register_google(key = Sys.getenv('GOOG_API_KEY'))

#define the area of the base map by using a bounding box 
mybasemap <- ggmap::get_map(location = c(left = table_sites %>% pull(long) %>% min()-0.01, 
                                    bottom = table_sites %>% pull(lat) %>% min()-0.01,
                                    right = table_sites %>% pull(long) %>% max()+0.01,
                                    top = table_sites %>% pull(lat) %>% max()+0.01),
                     source = "google",
                     zoom = 8,
                    maptype = "hybrid")



#define the area of the base map by using the middle. 
# mybasemap <- ggmap::get_map(location = c(lon = table_sites %>% pull(long) %>% mean(),
#                                          lat = table_sites %>% pull(lat) %>% mean())
#                             source = "google",
#                             zoom = "auto",
#                             maptype = "hybrid")

mymap <- ggmap::ggmap(mybasemap) + 
  geom_point(data = table_sites, 
             aes(x = long, y = lat),
             show.legend = F) 
  # ggsflabel::geom_sf_label(data = table_sites,
  #                          aes(x = long, y = lat, label = id),
  #                          # force = 100,
  #                          nudge_x = -2)

mymap
```



`r if(gitbook_on){knitr::asis_output("<br>")} else knitr::asis_output("<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>")`


```{r tab-sites, eval = T}
# build a table with overall details

table_sites %>% 
  sf::st_drop_geometry() %>% 
  arrange(id) %>% 
  select(id, stream_name, wsc_code, lat, long, sp_upstr = observedspp_upstr, pscis_assessment_comment) |> 
  fpr::fpr_kable(caption_text = 'Potential sample locations.', 
                 col_width_min = 6,
                 scroll = F) 
  # knitr::kable(caption = 'Potential sample locations.', booktabs = T) %>%
  # # kableExtra::kable_styling(c("condensed"),
  # #                           full_width = T,
  # #                           font_size = font_set) %>%
  # # kableExtra::column_spec(column = c(3,4,7), width_min = '1.0in') %>%
  # kableExtra::column_spec(column = c(7), width_max = '2.0in')
```



`r if(gitbook_on){knitr::asis_output("<br>")} else knitr::asis_output("<br><br><br><br><br>")`




```{r tab-fish}
tab_fish <- readr::read_csv(paste0(getwd(), '/data/fiss_species_table.csv'))

tab_fish %>% 
  my_kable(caption_text = 'Fish species recorded in the Parsnip River watershed group.')


```



